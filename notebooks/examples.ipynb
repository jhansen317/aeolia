{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aeolia Project Examples\n",
    "\n",
    "This notebook contains examples demonstrating the usage of the Aeolia project, which is built on PyTorch Geometric Temporal. The examples will cover data loading, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hansen/dev/aeolia\n",
      "./data/\n",
      "loading composer mapping default config\n",
      "loading processing statistics default config\n",
      "Configuration:\n",
      "K: 3\n",
      "num_nodes: 234\n",
      "input_dim: 32\n",
      "time_kernel: 3\n",
      "strides: [3, 3, 3]\n",
      "period: 200\n",
      "hidden_dim: 512\n",
      "num_blocks: 3\n",
      "Learning Rate: 0.0001\n",
      "Batch Size: 8\n",
      "Number of Epochs: 100\n",
      "Model Save Path: ./models/\n",
      "Data Path: ./data/\n",
      "Log Path: ./logs/\n",
      "Device: cpu\n",
      "Seed: 42\n",
      "num_composers: 42\n",
      "max_voices: 65\n",
      "Loading dataset...\n",
      "Loading dataset from /Users/hansen/dev/aeolia/data/raw_test\n",
      "loading composer mapping\n",
      "loading processing statistics\n",
      "loading rhythm mapping\n",
      "Building segment index...\n",
      "Found 153931 segments across 8287 files\n",
      "self.node_counts_per_layer: [234, 234, 116]\n",
      "Loading dataset from /Users/hansen/dev/aeolia/data/raw_test\n",
      "loading composer mapping\n",
      "loading processing statistics\n",
      "loading rhythm mapping\n",
      "Building segment index...\n",
      "Found 153931 segments across 8287 files\n",
      "self.node_counts_per_layer: [234, 234, 116]\n",
      "idx: 9645, file_path: /Users/hansen/dev/aeolia/data/raw_test/downland/downland_lachrymae_5_(c)icking-archive4.npz\n",
      "idx: 40458, file_path: /Users/hansen/dev/aeolia/data/raw_test/guerrero/guerrero_salve_regina_(c)icking-archive94.npz\n",
      "idx: 57780, file_path: /Users/hansen/dev/aeolia/data/raw_test/haydn/sonata_34_2_(c)iscenko.npz\n",
      "idx: 8047, file_path: /Users/hansen/dev/aeolia/data/raw_test/downland/dowland_sir_john_smith_almain_(c)bachovich.npz\n",
      "idx: 86559, file_path: /Users/hansen/dev/aeolia/data/raw_test/stravinsky/stravinsky_petrouchka_orchestra_concert_performance_ending_ver-1947_(c)laffay.npz\n",
      "idx: 100001, file_path: /Users/hansen/dev/aeolia/data/raw_test/ockeghem/ockeghem_missa_pro_defunctis_1_(c)icking-archive55.npz\n",
      "idx: 75274, file_path: /Users/hansen/dev/aeolia/data/raw_test/gesualdo/gesualdo_vi_libro_madrigali_5_(c)icking-archive5.npz\n",
      "idx: 59460, file_path: /Users/hansen/dev/aeolia/data/raw_test/haydn/18_menuets_&_aria_1765_(c)iscenko.npz\n",
      "in steps: 8\n",
      "out steps: 23\n",
      "in steps: 23\n",
      "out steps: 67\n",
      "in steps: 67\n",
      "out steps: 200\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "project_root = Path('/Users/hansen/dev/aeolia')\n",
    "sys.path.append(str(project_root))\n",
    "from src.models.astgcn import PolyphonyGCN\n",
    "from configs.default_config import DefaultConfig\n",
    "from src.data.dataset import MidiGraphDataset, temporal_graph_collate, to_dense_adj\n",
    "\n",
    "data_dir = project_root / \"data\" / \"raw_test\"\n",
    "config = DefaultConfig(project_root=project_root, config_path='/Users/hansen/dev/aeolia/configs/config.yml')\n",
    "print(\"Loading dataset...\")\n",
    "dataset = MidiGraphDataset(\n",
    "    npz_dir=data_dir,\n",
    "    seq_length=config.periods,\n",
    "    time_step=config.time_step,\n",
    "    max_pitch=128,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "dataset = MidiGraphDataset(\n",
    "    npz_dir=data_dir,\n",
    "    seq_length=config.periods,\n",
    "    time_step=config.time_step,\n",
    "    max_pitch=128,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Initialize DataLoader\n",
    "data_loader = DataLoader(dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=temporal_graph_collate)\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "# Initialize model\n",
    "model = PolyphonyGCN(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from src.data.dataset import MidiGraphDataset, temporal_graph_collate, to_dense_adj\n",
    "batch['features'][:, :, 0].shape\n",
    "testxmask = batch['features'][:, :, 0].view(-1).to(torch.bool)\n",
    "\n",
    "#to_dense_adj(batch['encoder_input_graphs'][0][0].edge_index).nonzero()\n",
    "#batch['encoder_input_graphs'][0][0]['num_nodes']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 248], edge_attr=[248], num_nodes=1872, x_mask=[8, 234], batch=[1872], ptr=[9])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['encoder_input_graphs'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('edge_index', tensor([[  47,   47,   47,   47,   47,   47,   47,   48,   48,   48,   48,   48,\n",
      "           48,   48,   49,   49,   49,   49,   49,   49,   49,   50,   50,   50,\n",
      "           50,   50,   50,   50,   51,   51,   51,   51,   51,   51,   51,   52,\n",
      "           52,   53,   53,   54,   55,   55,   56,   57,   57,   58,   59,   59,\n",
      "           59,   59,   59,   59,   59,   59,   59,   59,   59,  287,  287,  287,\n",
      "          287,  287,  287,  288,  288,  288,  288,  288,  288,  289,  289,  289,\n",
      "          289,  289,  289,  290,  290,  290,  290,  290,  290,  291,  291,  292,\n",
      "          292,  293,  293,  294,  294,  295,  296,  296,  297,  298,  298,  298,\n",
      "          298,  298,  298,  298,  298,  298,  513,  513,  513,  513,  514,  514,\n",
      "          514,  514,  515,  515,  516,  516,  517,  518,  519,  519,  519,  519,\n",
      "          519,  752,  752,  752,  752,  752,  752,  753,  753,  753,  753,  753,\n",
      "          753,  754,  754,  754,  754,  754,  754,  755,  755,  755,  755,  755,\n",
      "          755,  756,  756,  757,  757,  758,  758,  759,  759,  760,  761,  761,\n",
      "          761,  762,  762,  762,  762,  762,  762,  762,  762,  762,  987,  987,\n",
      "          987,  987,  987,  988,  988,  988,  988,  988,  989,  989,  989,  989,\n",
      "          989,  990,  990,  991,  991,  992,  992,  993,  993,  994,  995,  995,\n",
      "          995,  995,  995,  995,  995, 1237, 1237, 1237, 1237, 1237, 1238, 1238,\n",
      "         1238, 1238, 1238, 1239, 1239, 1239, 1239, 1239, 1240, 1240, 1241, 1241,\n",
      "         1242, 1242, 1243, 1244, 1244, 1245, 1245, 1245, 1245, 1245, 1245, 1245,\n",
      "         1637, 1696, 1696, 1696, 1696, 1697, 1697, 1697, 1697, 1698, 1698, 1699,\n",
      "         1699, 1700, 1700, 1701, 1701, 1701, 1701, 1701],\n",
      "        [  47,   55,   59,   63,   67,  132,  233,   47,   55,   59,   63,   67,\n",
      "          131,  233,   47,   55,   59,   63,   67,  130,  233,   47,   55,   59,\n",
      "           63,   67,  129,  233,   47,   55,   59,   63,   67,  128,  233,  209,\n",
      "          233,  209,  233,  233,  217,  233,  233,  128,  129,  131,   47,   55,\n",
      "           59,   63,   67,  128,  129,  130,  131,  132,  233,  287,  291,  303,\n",
      "          306,  365,  467,  287,  291,  303,  306,  364,  467,  287,  291,  303,\n",
      "          306,  363,  467,  287,  291,  303,  306,  362,  467,  435,  467,  450,\n",
      "          467,  443,  467,  443,  467,  362,  364,  365,  363,  287,  291,  303,\n",
      "          306,  362,  363,  364,  365,  467,  513,  530,  598,  701,  513,  530,\n",
      "          596,  701,  669,  701,  668,  701,  598,  596,  513,  530,  596,  598,\n",
      "          701,  752,  756,  764,  771,  830,  935,  752,  756,  764,  771,  831,\n",
      "          935,  752,  756,  764,  771,  832,  935,  752,  756,  764,  771,  833,\n",
      "          935,  919,  935,  919,  935,  919,  935,  903,  935,  833,  830,  831,\n",
      "          832,  752,  756,  764,  771,  830,  831,  832,  833,  935,  987,  999,\n",
      "         1011, 1075, 1169,  987,  999, 1011, 1080, 1169,  987,  999, 1011, 1066,\n",
      "         1169, 1131, 1169, 1131, 1169, 1133, 1169, 1066, 1075, 1080,  987,  999,\n",
      "         1011, 1066, 1075, 1080, 1169, 1237, 1240, 1252, 1298, 1403, 1237, 1240,\n",
      "         1252, 1299, 1403, 1237, 1240, 1252, 1300, 1403, 1395, 1403, 1379, 1403,\n",
      "         1395, 1403, 1299, 1298, 1300, 1237, 1240, 1252, 1298, 1299, 1300, 1403,\n",
      "         1637, 1696, 1700, 1768, 1871, 1696, 1700, 1766, 1871, 1838, 1871, 1838,\n",
      "         1871, 1766, 1768, 1696, 1700, 1766, 1768, 1871]]))\n",
      "1 ('edge_attr', tensor([0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 1.0000, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 1.0000, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252,\n",
      "        0.6220, 0.6220, 0.6220, 0.6220, 0.4252, 0.4252, 0.4252, 0.6220, 0.4252,\n",
      "        0.6220, 0.6220, 0.4252, 1.0000, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693,\n",
      "        0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693,\n",
      "        0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693,\n",
      "        0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693,\n",
      "        0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693, 0.6693,\n",
      "        0.6693, 0.6693, 0.6693, 1.0000, 0.6220, 0.6220, 0.6220, 0.6299, 0.6299,\n",
      "        0.6220, 0.6220, 0.6220, 0.6220, 0.6220, 0.6220, 0.6220, 0.6220, 0.7717,\n",
      "        0.7717, 0.7717, 0.7717, 0.6299, 0.6299, 0.6220, 0.6220, 0.7717, 0.6299,\n",
      "        0.6220, 0.6299, 0.6220, 0.7717, 0.7717, 0.6299, 0.6220, 1.0000, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874, 0.7874,\n",
      "        0.7874, 0.7874, 1.0000, 1.0000, 0.6220, 0.6220, 0.6299, 0.6299, 0.6220,\n",
      "        0.6220, 0.6220, 0.6220, 0.6220, 0.6220, 0.6299, 0.6299, 0.6220, 0.6299,\n",
      "        0.6299, 0.6220, 0.6220, 0.6299, 1.0000]))\n",
      "2 ('num_nodes', 1872)\n",
      "3 ('x_mask', tensor([[False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False, False,  True]]))\n",
      "4 ('batch', tensor([0, 0, 0,  ..., 7, 7, 7]))\n",
      "5 ('ptr', tensor([   0,  234,  468,  702,  936, 1170, 1404, 1638, 1872]))\n"
     ]
    }
   ],
   "source": [
    "for batch_id, item in enumerate(batch['encoder_input_graphs'][0][0]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 248], edge_attr=[248], num_nodes=1872, x_mask=[8, 234], batch=[1872], ptr=[9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['encoder_input_graphs'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  47,   47,   47,   47,   47,   47,   47,   48,   48,   48,   48,   48,\n",
       "           48,   48,   49,   49,   49,   49,   49,   49,   49,   50,   50,   50,\n",
       "           50,   50,   50,   50,   51,   51,   51,   51,   51,   51,   51,   52,\n",
       "           52,   53,   53,   54,   55,   55,   56,   57,   57,   58,   59,   59,\n",
       "           59,   59,   59,   59,   59,   59,   59,   59,   59,  287,  287,  287,\n",
       "          287,  287,  287,  288,  288,  288,  288,  288,  288,  289,  289,  289,\n",
       "          289,  289,  289,  290,  290,  290,  290,  290,  290,  291,  291,  292,\n",
       "          292,  293,  293,  294,  294,  295,  296,  296,  297,  298,  298,  298,\n",
       "          298,  298,  298,  298,  298,  298,  513,  513,  513,  513,  514,  514,\n",
       "          514,  514,  515,  515,  516,  516,  517,  518,  519,  519,  519,  519,\n",
       "          519,  752,  752,  752,  752,  752,  752,  753,  753,  753,  753,  753,\n",
       "          753,  754,  754,  754,  754,  754,  754,  755,  755,  755,  755,  755,\n",
       "          755,  756,  756,  757,  757,  758,  758,  759,  759,  760,  761,  761,\n",
       "          761,  762,  762,  762,  762,  762,  762,  762,  762,  762,  987,  987,\n",
       "          987,  987,  987,  988,  988,  988,  988,  988,  989,  989,  989,  989,\n",
       "          989,  990,  990,  991,  991,  992,  992,  993,  993,  994,  995,  995,\n",
       "          995,  995,  995,  995,  995, 1237, 1237, 1237, 1237, 1237, 1238, 1238,\n",
       "         1238, 1238, 1238, 1239, 1239, 1239, 1239, 1239, 1240, 1240, 1241, 1241,\n",
       "         1242, 1242, 1243, 1244, 1244, 1245, 1245, 1245, 1245, 1245, 1245, 1245,\n",
       "         1637, 1696, 1696, 1696, 1696, 1697, 1697, 1697, 1697, 1698, 1698, 1699,\n",
       "         1699, 1700, 1700, 1701, 1701, 1701, 1701, 1701],\n",
       "        [  47,   55,   59,   63,   67,  132,  233,   47,   55,   59,   63,   67,\n",
       "          131,  233,   47,   55,   59,   63,   67,  130,  233,   47,   55,   59,\n",
       "           63,   67,  129,  233,   47,   55,   59,   63,   67,  128,  233,  209,\n",
       "          233,  209,  233,  233,  217,  233,  233,  128,  129,  131,   47,   55,\n",
       "           59,   63,   67,  128,  129,  130,  131,  132,  233,  287,  291,  303,\n",
       "          306,  365,  467,  287,  291,  303,  306,  364,  467,  287,  291,  303,\n",
       "          306,  363,  467,  287,  291,  303,  306,  362,  467,  435,  467,  450,\n",
       "          467,  443,  467,  443,  467,  362,  364,  365,  363,  287,  291,  303,\n",
       "          306,  362,  363,  364,  365,  467,  513,  530,  598,  701,  513,  530,\n",
       "          596,  701,  669,  701,  668,  701,  598,  596,  513,  530,  596,  598,\n",
       "          701,  752,  756,  764,  771,  830,  935,  752,  756,  764,  771,  831,\n",
       "          935,  752,  756,  764,  771,  832,  935,  752,  756,  764,  771,  833,\n",
       "          935,  919,  935,  919,  935,  919,  935,  903,  935,  833,  830,  831,\n",
       "          832,  752,  756,  764,  771,  830,  831,  832,  833,  935,  987,  999,\n",
       "         1011, 1075, 1169,  987,  999, 1011, 1080, 1169,  987,  999, 1011, 1066,\n",
       "         1169, 1131, 1169, 1131, 1169, 1133, 1169, 1066, 1075, 1080,  987,  999,\n",
       "         1011, 1066, 1075, 1080, 1169, 1237, 1240, 1252, 1298, 1403, 1237, 1240,\n",
       "         1252, 1299, 1403, 1237, 1240, 1252, 1300, 1403, 1395, 1403, 1379, 1403,\n",
       "         1395, 1403, 1299, 1298, 1300, 1237, 1240, 1252, 1298, 1299, 1300, 1403,\n",
       "         1637, 1696, 1700, 1768, 1871, 1696, 1700, 1766, 1871, 1838, 1871, 1838,\n",
       "         1871, 1766, 1768, 1696, 1700, 1766, 1768, 1871]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['encoder_input_graphs'][0][0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 234])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['encoder_input_graphs'][0][0].x_mask.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1872])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_node_ids = torch.unique(batch['encoder_input_graphs'][0][0].edge_index)\n",
    "sorted_slice_node_ids = torch.sort(slice_node_ids).values.view(-1)\n",
    "x = batch['features'][:, :, 0].view(-1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  47,   48,   49,   50,   51,   52,   53,   54,   55,   56,   57,   58,\n",
       "          59,   63,   67,  128,  129,  130,  131,  132,  209,  217,  233,  287,\n",
       "         288,  289,  290,  291,  292,  293,  294,  295,  296,  297,  298,  303,\n",
       "         306,  362,  363,  364,  365,  435,  443,  450,  467,  513,  514,  515,\n",
       "         516,  517,  518,  519,  530,  596,  598,  668,  669,  701,  752,  753,\n",
       "         754,  755,  756,  757,  758,  759,  760,  761,  762,  764,  771,  830,\n",
       "         831,  832,  833,  903,  919,  935,  987,  988,  989,  990,  991,  992,\n",
       "         993,  994,  995,  999, 1011, 1066, 1075, 1080, 1131, 1133, 1169, 1237,\n",
       "        1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1252, 1298, 1299, 1300,\n",
       "        1379, 1395, 1403, 1637, 1696, 1697, 1698, 1699, 1700, 1701, 1766, 1768,\n",
       "        1838, 1871])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(slice_node_ids).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  55,   63,   67,  128,  129,  131,  209,  217,  233,  287,  291,  303,\n",
       "         306,  362,  363,  364,  365,  435,  443,  450,  467,  513,  530,  596,\n",
       "         598,  668,  669,  701,  752,  756,  764,  771,  830,  831,  832,  833,\n",
       "         903,  919,  935,  987,  999, 1011, 1066, 1075, 1080, 1131, 1133, 1169,\n",
       "        1237, 1240, 1252, 1298, 1299, 1300, 1379, 1395, 1403, 1637, 1696, 1700,\n",
       "        1766, 1768, 1838, 1871])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_to_index(testxmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import coalesce, dense_to_sparse, to_dense_adj, mask_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
